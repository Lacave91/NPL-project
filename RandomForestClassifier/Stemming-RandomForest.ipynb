{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a notebook for Random Forest  training a model to be able to categorize fake vs real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function to apply text preprocesing to the datasets. </br>\n",
    "Load the data formating it correctly for easy use and apply the preporcessing </br>\n",
    "Split the data into a label and title columns so es easy to access only the title for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove Numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra white space\n",
    "    text = text.strip()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title\n",
      "0      0  donald trump sends out embarrassing new year‚s...\n",
      "1      0  drunk bragging trump staffer started russian c...\n",
      "2      0  sheriff david clarke becomes an internet joke ...\n",
      "3      0  trump is so obsessed he even has obama‚s name ...\n",
      "4      0  pope francis just called out donald trump duri...\n",
      "  label                                              title\n",
      "0     2  copycat muslim terrorist arrested with assault...\n",
      "1     2  wow! chicago protester caught on camera admits...\n",
      "2     2   germany's fdp look to fill schaeuble's big shoes\n",
      "3     2  mi school sends welcome back packet warning ki...\n",
      "4     2  u.n. seeks 'massive' aid boost amid rohingya '...\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets formating them correctly for ease of use\n",
    "train_data = pd.read_csv(\n",
    "    r\"..\\training_data_lowercase.csv\",\n",
    "    sep='\\t',  # TAB serparator\n",
    "    header=None,\n",
    "    names=['label', 'title']\n",
    ")\n",
    "\n",
    "test_data = pd.read_csv(\n",
    "    r\"..\\testing_data_lowercase_nolabels.csv\",\n",
    "    sep='\\t',  # TAB serparator\n",
    "    header=None,\n",
    "    names=['label', 'title']\n",
    ")\n",
    "\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    donald trump sends embarrassing new years eve ...\n",
      "1    drunk bragging trump staffer started russian c...\n",
      "2    sheriff david clarke becomes internet joke thr...\n",
      "3    trump obsessed even obamas name coded website ...\n",
      "4    pope francis called donald trump christmas speech\n",
      "Name: title, dtype: object\n",
      "0    copycat muslim terrorist arrested assault weapons\n",
      "1    wow chicago protester caught camera admits vio...\n",
      "2          germanys fdp look fill schaeubles big shoes\n",
      "3    mi school sends welcome back packet warning ki...\n",
      "4    un seeks massive aid boost amid rohingya emerg...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the 'title' column\n",
    "train_data['title'] = train_data['title'].apply(clean_text)\n",
    "test_data['title'] = test_data['title'].apply(clean_text)\n",
    "\n",
    "print(train_data['title'].head())\n",
    "print(test_data['title'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenice and stemming to prepare the titles to convert to numbers using TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title\n",
      "0      0  [donald, trump, sends, embarrassing, new, year...\n",
      "1      0  [drunk, bragging, trump, staffer, started, rus...\n",
      "2      0  [sheriff, david, clarke, becomes, internet, jo...\n",
      "3      0  [trump, obsessed, even, obamas, name, coded, w...\n",
      "4      0  [pope, francis, called, donald, trump, christm...\n",
      "  label                                              title\n",
      "0     2  [copycat, muslim, terrorist, arrested, assault...\n",
      "1     2  [wow, chicago, protester, caught, camera, admi...\n",
      "2     2  [germanys, fdp, look, fill, schaeubles, big, s...\n",
      "3     2  [mi, school, sends, welcome, back, packet, war...\n",
      "4     2  [un, seeks, massive, aid, boost, amid, rohingy...\n"
     ]
    }
   ],
   "source": [
    "# Tokenize train and testing data\n",
    "def tokenizeDataframe(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "train_data['title'] = train_data['title'].apply(tokenizeDataframe)\n",
    "test_data['title'] = test_data['title'].apply(tokenizeDataframe)\n",
    "\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Tokens: 0    [donald, trump, send, embarrass, new, year, ev...\n",
      "1    [drunk, brag, trump, staffer, start, russian, ...\n",
      "2    [sheriff, david, clark, becom, internet, joke,...\n",
      "3    [trump, obsess, even, obama, name, code, websi...\n",
      "4    [pope, franci, call, donald, trump, christma, ...\n",
      "Name: title, dtype: object\n",
      "Stemmed Tokens: 0    [copycat, muslim, terrorist, arrest, assault, ...\n",
      "1    [wow, chicago, protest, caught, camera, admit,...\n",
      "2      [germani, fdp, look, fill, schaeubl, big, shoe]\n",
      "3    [mi, school, send, welcom, back, packet, warn,...\n",
      "4    [un, seek, massiv, aid, boost, amid, rohingya,...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# stemming for simplifying the words\n",
    "stemmer = PorterStemmer()\n",
    "train_data['title'] = train_data['title'].apply(lambda title: [stemmer.stem(word) for word in title])\n",
    "test_data['title'] = test_data['title'].apply(lambda title: [stemmer.stem(word) for word in title])\n",
    "\n",
    "print(\"Stemmed Tokens:\", train_data['title'].head())\n",
    "print(\"Stemmed Tokens:\", test_data['title'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply TF-IDF to the dataset to conver the words into numerical values for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Feature Names: ['aar' 'aardvark' 'aaron' ... 'zurich' 'éblacklivesmatt' 'øqu']\n",
      "\n",
      "TF-IDF Representation:\n",
      " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 297213 stored elements and shape (34152, 15288)>\n",
      "  Coords\tValues\n",
      "  (0, 3893)\t0.26300298396826993\n",
      "  (0, 13808)\t0.11204501106282502\n",
      "  (0, 11970)\t0.3602988733376756\n",
      "  (0, 4270)\t0.37010155056710026\n",
      "  (0, 9017)\t0.23511756235894\n",
      "  (0, 15175)\t0.29851930864715037\n",
      "  (0, 4496)\t0.4591731728534708\n",
      "  (0, 8437)\t0.34775165044814654\n",
      "  (0, 3818)\t0.418711895265266\n",
      "  (1, 13808)\t0.11063881854606479\n",
      "  (1, 4037)\t0.464824398415991\n",
      "  (1, 1676)\t0.39238024516639897\n",
      "  (1, 12723)\t0.3940683663022418\n",
      "  (1, 12761)\t0.3395042582851444\n",
      "  (1, 11579)\t0.28131933141472215\n",
      "  (1, 2650)\t0.4134569577342199\n",
      "  (1, 6972)\t0.31160043778976426\n",
      "  (2, 12107)\t0.3094003802580648\n",
      "  (2, 3318)\t0.33688451396812097\n",
      "  (2, 2469)\t0.3727838315345167\n",
      "  (2, 1222)\t0.2904163960257186\n",
      "  (2, 6938)\t0.2882712362408179\n",
      "  (2, 7219)\t0.3167886136850657\n",
      "  (2, 13474)\t0.25633307087507695\n",
      "  (2, 10158)\t0.4206937156918041\n",
      "  :\t:\n",
      "  (34148, 10709)\t0.3886537566480528\n",
      "  (34148, 9154)\t0.4398717401637831\n",
      "  (34149, 10361)\t0.21862175266724565\n",
      "  (34149, 10002)\t0.34410857443656184\n",
      "  (34149, 7127)\t0.32852949437530277\n",
      "  (34149, 14617)\t0.29317892514558236\n",
      "  (34149, 7365)\t0.32473823949346636\n",
      "  (34149, 13039)\t0.3554839846856934\n",
      "  (34149, 236)\t0.33554367606461294\n",
      "  (34149, 11073)\t0.3780429868483298\n",
      "  (34149, 4091)\t0.3906129304393713\n",
      "  (34150, 14739)\t0.29134577076465995\n",
      "  (34150, 4205)\t0.2744178145064773\n",
      "  (34150, 8137)\t0.4150893265254872\n",
      "  (34150, 7127)\t0.36918573799152843\n",
      "  (34150, 3912)\t0.35319323903788213\n",
      "  (34150, 8290)\t0.3017196942191079\n",
      "  (34150, 10136)\t0.3255190471179833\n",
      "  (34150, 15)\t0.45768150365615634\n",
      "  (34151, 6890)\t0.40511287045067357\n",
      "  (34151, 5201)\t0.3163664764786985\n",
      "  (34151, 10166)\t0.30209136821325655\n",
      "  (34151, 3828)\t0.4303723861679186\n",
      "  (34151, 3530)\t0.5305061607038639\n",
      "  (34151, 2131)\t0.4217575638753731\n"
     ]
    }
   ],
   "source": [
    "# Join tokenized words back into strings\n",
    "train_data['title'] = train_data['title'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(train_data['title'])\n",
    "\n",
    "print(\"\\nTF-IDF Feature Names:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Representation:\\n\", X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_tfidf, train_data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train+validation into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42) \n",
    "\n",
    "# Initialize the logicti regresion model\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    max_depth=10,  # Limit depth\n",
    "    min_samples_split=5,  # Require more samples to split\n",
    "    min_samples_leaf=2,  # Require more samples in leaves\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on training set\n",
    "y_train_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.8452903855539288\n",
      "Training Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.96      0.86     10533\n",
      "           1       0.94      0.73      0.82      9957\n",
      "\n",
      "    accuracy                           0.85     20490\n",
      "   macro avg       0.86      0.84      0.84     20490\n",
      "weighted avg       0.86      0.85      0.84     20490\n",
      "\n",
      "Training R²: 0.3806721222532883\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Validation Accuracy: 0.8341384863123994\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.85      3510\n",
      "           1       0.93      0.71      0.81      3321\n",
      "\n",
      "    accuracy                           0.83      6831\n",
      "   macro avg       0.85      0.83      0.83      6831\n",
      "weighted avg       0.85      0.83      0.83      6831\n",
      "\n",
      "Validation R²: 0.336045676696083\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Accuracy: 0.8312106572976138\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.85      3529\n",
      "           1       0.93      0.71      0.80      3302\n",
      "\n",
      "    accuracy                           0.83      6831\n",
      "   macro avg       0.85      0.83      0.83      6831\n",
      "weighted avg       0.85      0.83      0.83      6831\n",
      "\n",
      "Test R²: 0.32409623541482635\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on training set\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "train_report = classification_report(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "# Evaluate the model on validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_report = classification_report(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy}\")\n",
    "print(\"Training Classification Report:\\n\", train_report)\n",
    "print(f\"Training R²: {train_r2}\")\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(\"Validation Classification Report:\\n\", val_report)\n",
    "print(f\"Validation R²: {val_r2}\")\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(\"Test Classification Report:\\n\", test_report)\n",
    "print(f\"Test R²: {test_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8312106572976138\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.95      0.85      3529\n",
      "           1       0.93      0.71      0.80      3302\n",
      "\n",
      "    accuracy                           0.83      6831\n",
      "   macro avg       0.85      0.83      0.83      6831\n",
      "weighted avg       0.85      0.83      0.83      6831\n",
      "\n",
      "Test R²: 0.32409623541482635\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(\"Test Classification Report:\\n\", test_report)\n",
    "print(f\"Test R²: {test_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Calculate the confusion matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m conf_matrix \u001b[38;5;241m=\u001b[39m confusion_matrix(y_test, \u001b[43my_pred\u001b[49m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the confusion matrix\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title\n",
      "0      0  copycat muslim terrorist arrested with assault...\n",
      "1      0  wow! chicago protester caught on camera admits...\n",
      "2      0   germany's fdp look to fill schaeuble's big shoes\n",
      "3      0  mi school sends welcome back packet warning ki...\n",
      "4      0  u.n. seeks 'massive' aid boost amid rohingya '...\n"
     ]
    }
   ],
   "source": [
    "X_test_unlabeled = tfidf_vectorizer.transform(test_data['title'].apply(lambda tokens: ' '.join(tokens)))\n",
    "\n",
    "# Predict labels for the unlabeled data\n",
    "predicted_labels = model.predict(X_test_unlabeled)\n",
    "\n",
    "test_data['label'] = predicted_labels\n",
    "\n",
    "# Display the first few rows of the updated testing data\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ":white_check_mark: Predictions exported successfully in correct format!\n"
     ]
    }
   ],
   "source": [
    "# Make sure title is string, not list\n",
    "test_data['title'] = test_data['title'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "# Export respecting original format\n",
    "test_data[['label', 'title']].to_csv(\n",
    "    r'stemming_rf_test_data.csv',\n",
    "    sep='\\t',  # TAB separator\n",
    "    index=False,\n",
    "    header=False  # No column names\n",
    ")\n",
    "print(\"\\n:white_check_mark: Predictions exported successfully in correct format!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
