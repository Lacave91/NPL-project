{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a notebook for Logistical Regression training a model to be able to categorize fake vs real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a function to apply text preprocesing to the datasets. </br>\n",
    "Load the data formating it correctly for easy use and apply the preporcessing </br>\n",
    "Split the data into a label and title columns so es easy to access only the title for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove special characters\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove Numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Remove extra white space\n",
    "    text = text.strip()\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Remove stopwords\n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title\n",
      "0      0  donald trump sends out embarrassing new year‚s...\n",
      "1      0  drunk bragging trump staffer started russian c...\n",
      "2      0  sheriff david clarke becomes an internet joke ...\n",
      "3      0  trump is so obsessed he even has obama‚s name ...\n",
      "4      0  pope francis just called out donald trump duri...\n",
      "  label                                              title\n",
      "0     2  copycat muslim terrorist arrested with assault...\n",
      "1     2  wow! chicago protester caught on camera admits...\n",
      "2     2   germany's fdp look to fill schaeuble's big shoes\n",
      "3     2  mi school sends welcome back packet warning ki...\n",
      "4     2  u.n. seeks 'massive' aid boost amid rohingya '...\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets formating them correctly for ease of use\n",
    "train_data = pd.read_csv(\n",
    "    r\"..\\training_data_lowercase.csv\",\n",
    "    sep='\\t',  # TAB serparator\n",
    "    header=None,\n",
    "    names=['label', 'title']\n",
    ")\n",
    "\n",
    "test_data = pd.read_csv(\n",
    "    r\"..\\testing_data_lowercase_nolabels.csv\",\n",
    "    sep='\\t',  # TAB serparator\n",
    "    header=None,\n",
    "    names=['label', 'title']\n",
    ")\n",
    "\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    donald trump sends out embarrassing new year‚s...\n",
      "1    drunk bragging trump staffer started russian c...\n",
      "2    sheriff david clarke becomes an internet joke ...\n",
      "3    trump is so obsessed he even has obama‚s name ...\n",
      "4    pope francis just called out donald trump duri...\n",
      "Name: title, dtype: object\n",
      "0    copycat muslim terrorist arrested with assault...\n",
      "1    wow! chicago protester caught on camera admits...\n",
      "2     germany's fdp look to fill schaeuble's big shoes\n",
      "3    mi school sends welcome back packet warning ki...\n",
      "4    u.n. seeks 'massive' aid boost amid rohingya '...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to the 'title' column\n",
    "# train_data['title'] = train_data['title'].apply(clean_text)\n",
    "# test_data['title'] = test_data['title'].apply(clean_text)\n",
    "\n",
    "print(train_data['title'].head())\n",
    "print(test_data['title'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenice and stemming to prepare the titles to convert to numbers using TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title\n",
      "0      0  donald trump sends out embarrassing new year‚s...\n",
      "1      0  drunk bragging trump staffer started russian c...\n",
      "2      0  sheriff david clarke becomes an internet joke ...\n",
      "3      0  trump is so obsessed he even has obama‚s name ...\n",
      "4      0  pope francis just called out donald trump duri...\n",
      "  label                                              title\n",
      "0     2  copycat muslim terrorist arrested with assault...\n",
      "1     2  wow! chicago protester caught on camera admits...\n",
      "2     2   germany's fdp look to fill schaeuble's big shoes\n",
      "3     2  mi school sends welcome back packet warning ki...\n",
      "4     2  u.n. seeks 'massive' aid boost amid rohingya '...\n"
     ]
    }
   ],
   "source": [
    "# Tokenize train and testing data\n",
    "def tokenizeDataframe(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "# train_data['title'] = train_data['title'].apply(tokenizeDataframe)\n",
    "# test_data['title'] = test_data['title'].apply(tokenizeDataframe)\n",
    "\n",
    "print(train_data.head())\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmed Tokens: 0    donald trump sends out embarrassing new year‚s...\n",
      "1    drunk bragging trump staffer started russian c...\n",
      "2    sheriff david clarke becomes an internet joke ...\n",
      "3    trump is so obsessed he even has obama‚s name ...\n",
      "4    pope francis just called out donald trump duri...\n",
      "Name: title, dtype: object\n",
      "Stemmed Tokens: 0    copycat muslim terrorist arrested with assault...\n",
      "1    wow! chicago protester caught on camera admits...\n",
      "2     germany's fdp look to fill schaeuble's big shoes\n",
      "3    mi school sends welcome back packet warning ki...\n",
      "4    u.n. seeks 'massive' aid boost amid rohingya '...\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# stemming for simplifying the words\n",
    "stemmer = PorterStemmer()\n",
    "# train_data['title'] = train_data['title'].apply(lambda title: [stemmer.stem(word) for word in title])\n",
    "# test_data['title'] = test_data['title'].apply(lambda title: [stemmer.stem(word) for word in title])\n",
    "\n",
    "print(\"Stemmed Tokens:\", train_data['title'].head())\n",
    "print(\"Stemmed Tokens:\", test_data['title'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply TF-IDF to the dataset to conver the words into numerical values for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TF-IDF Feature Names: ['00' '0045' '0111' ... 'îk' 'îpence' 'øqu']\n",
      "\n",
      "TF-IDF Representation:\n",
      " <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 390264 stored elements and shape (34152, 18673)>\n",
      "  Coords\tValues\n",
      "  (0, 5341)\t0.23594607631008147\n",
      "  (0, 17168)\t0.09871680270440454\n",
      "  (0, 14809)\t0.360810448061762\n",
      "  (0, 11760)\t0.2251642878332491\n",
      "  (0, 5782)\t0.36784073721965305\n",
      "  (0, 11261)\t0.21081145630832848\n",
      "  (0, 18556)\t0.2795008715924424\n",
      "  (0, 6110)\t0.41238633616840253\n",
      "  (0, 10595)\t0.31514400469546994\n",
      "  (0, 16720)\t0.22142744799533873\n",
      "  (0, 9017)\t0.18273121389310565\n",
      "  (0, 5242)\t0.3795171214730221\n",
      "  (1, 17168)\t0.10035834003226096\n",
      "  (1, 5514)\t0.4328255787960555\n",
      "  (1, 2371)\t0.42168063909640197\n",
      "  (1, 15785)\t0.3923235418466126\n",
      "  (1, 15837)\t0.3982062340521523\n",
      "  (1, 14360)\t0.26389760407113516\n",
      "  (1, 3525)\t0.38008086220062226\n",
      "  (1, 8953)\t0.3133469115315427\n",
      "  (2, 14997)\t0.27978598468001187\n",
      "  (2, 4445)\t0.30178363237263756\n",
      "  (2, 3325)\t0.3361754376926148\n",
      "  (2, 1830)\t0.3090971771169678\n",
      "  (2, 985)\t0.21756879206432397\n",
      "  :\t:\n",
      "  (34149, 9356)\t0.28570733463791465\n",
      "  (34149, 769)\t0.29363448164602224\n",
      "  (34149, 13592)\t0.3684213423877298\n",
      "  (34149, 5577)\t0.342388866860338\n",
      "  (34149, 16190)\t0.4861806017052917\n",
      "  (34150, 1287)\t0.1981947739747399\n",
      "  (34150, 8108)\t0.23473868623008481\n",
      "  (34150, 5340)\t0.28395099379165817\n",
      "  (34150, 5727)\t0.23086956553647428\n",
      "  (34150, 7931)\t0.24673629866722585\n",
      "  (34150, 10287)\t0.34067380862509106\n",
      "  (34150, 9105)\t0.3029781306795194\n",
      "  (34150, 18420)\t0.2684858228803104\n",
      "  (34150, 10430)\t0.24821421686612408\n",
      "  (34150, 2667)\t0.267491410354072\n",
      "  (34150, 18061)\t0.28258082427454867\n",
      "  (34150, 12490)\t0.27694596329693616\n",
      "  (34150, 444)\t0.375708513301308\n",
      "  (34151, 8793)\t0.39948884452170047\n",
      "  (34151, 1009)\t0.18926401401364787\n",
      "  (34151, 6893)\t0.34091172068957015\n",
      "  (34151, 12522)\t0.2825874962923785\n",
      "  (34151, 5264)\t0.42867012907067703\n",
      "  (34151, 4728)\t0.5174493724756869\n",
      "  (34151, 2911)\t0.39623145900456547\n"
     ]
    }
   ],
   "source": [
    "# Join tokenized words back into strings\n",
    "# train_data['title'] = train_data['title'].apply(lambda tokens: ' '.join(tokens))\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(train_data['title'])\n",
    "\n",
    "print(\"\\nTF-IDF Feature Names:\", tfidf_vectorizer.get_feature_names_out())\n",
    "print(\"\\nTF-IDF Representation:\\n\", X_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train+validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_tfidf, train_data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split train+validation into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42)\n",
    "# Initialize the logicti regresion model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Predict on test set\n",
    "y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9351485873225004\n",
      "Validation Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.94      3510\n",
      "           1       0.92      0.95      0.93      3321\n",
      "\n",
      "    accuracy                           0.94      6831\n",
      "   macro avg       0.94      0.94      0.94      6831\n",
      "weighted avg       0.94      0.94      0.94      6831\n",
      "\n",
      "Validation R²: 0.74039561763139\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Test Accuracy: 0.9411506368028107\n",
      "Test Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94      3529\n",
      "           1       0.93      0.95      0.94      3302\n",
      "\n",
      "    accuracy                           0.94      6831\n",
      "   macro avg       0.94      0.94      0.94      6831\n",
      "weighted avg       0.94      0.94      0.94      6831\n",
      "\n",
      "Test R²: 0.7643423127812318\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on validation set\n",
    "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "val_report = classification_report(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Evaluate the model on test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {val_accuracy}\")\n",
    "print(\"Validation Classification Report:\\n\", val_report)\n",
    "print(f\"Validation R²: {val_r2}\")\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(\"Test Classification Report:\\n\", test_report)\n",
    "print(f\"Test R²: {test_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=['Fake', 'Real'], yticklabels=['Fake', 'Real'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label                                              title\n",
      "0      1  copycat muslim terrorist arrested with assault...\n",
      "1      1  wow! chicago protester caught on camera admits...\n",
      "2      1   germany's fdp look to fill schaeuble's big shoes\n",
      "3      1  mi school sends welcome back packet warning ki...\n",
      "4      1  u.n. seeks 'massive' aid boost amid rohingya '...\n"
     ]
    }
   ],
   "source": [
    "X_test_unlabeled = tfidf_vectorizer.transform(test_data['title'].apply(lambda tokens: ' '.join(tokens)))\n",
    "\n",
    "# Predict labels for the unlabeled data\n",
    "predicted_labels = model.predict(X_test_unlabeled)\n",
    "\n",
    "test_data['label'] = predicted_labels\n",
    "\n",
    "# Display the first few rows of the updated testing data\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ":white_check_mark: Predictions exported successfully in correct format!\n"
     ]
    }
   ],
   "source": [
    "# Make sure title is string, not list\n",
    "test_data['title'] = test_data['title'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "# Export respecting original format\n",
    "test_data[['label', 'title']].to_csv(\n",
    "    r'LogisticalRegresion_test_data.csv',\n",
    "    sep='\\t',  # TAB separator\n",
    "    index=False,\n",
    "    header=False  # No column names\n",
    ")\n",
    "print(\"\\n:white_check_mark: Predictions exported successfully in correct format!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
